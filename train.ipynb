{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a314cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFGPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986244c7",
   "metadata": {},
   "source": [
    "# 모델 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1e456a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.1.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'lm_head.weight', 'transformer.h.0.attn.masked_bias', 'transformer.h.2.attn.masked_bias']\n",
      "- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# bos_token 등은 모델마다 달라서 아래와 같이 설정\n",
    "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2',\n",
    "                                            bos_token='<s>',\n",
    "                                            eos_token='</s>',\n",
    "                                            pad_token='<pad>')\n",
    "model = TFGPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2', from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb17a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2lm_head_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLay  multiple                  125164032 \n",
      " er)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125164032 (477.46 MB)\n",
      "Trainable params: 125164032 (477.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff892d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50619bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data1 = pd.read_csv(\"data/chatbot_data.csv\")\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6360803e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>req</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>너 좋아하는 차 종류 있어?</td>\n",
       "      <td>무슨 차? 자동차? 마시는 차?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ㅋㅋ 마시는 차 말한 거야!</td>\n",
       "      <td>아하 나 둥글레, 옥수수, 보리차 좋아해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>완전 곡물류 좋아하네 ㅋㅋ</td>\n",
       "      <td>야쓰 끓이기 귀찮아서 냉침해 먹어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그럼 오래 걸리지 않아?</td>\n",
       "      <td>끓이는 것보다는 훨씬 오래 걸리지 ㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>근데 냉침 하는 것도 귀찮겠다 ㅜㅠ</td>\n",
       "      <td>응! 그래서 매일은 안 먹고 가끔 마셔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   req                     res\n",
       "0      너 좋아하는 차 종류 있어?       무슨 차? 자동차? 마시는 차?\n",
       "1      ㅋㅋ 마시는 차 말한 거야!  아하 나 둥글레, 옥수수, 보리차 좋아해\n",
       "2       완전 곡물류 좋아하네 ㅋㅋ      야쓰 끓이기 귀찮아서 냉침해 먹어\n",
       "3        그럼 오래 걸리지 않아?    끓이는 것보다는 훨씬 오래 걸리지 ㅠ\n",
       "4  근데 냉침 하는 것도 귀찮겠다 ㅜㅠ   응! 그래서 매일은 안 먹고 가끔 마셔"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"data/all_data.csv\")\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33034985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('12시 땡!', '하루가 또 가네요.')]\n",
      "[('너 좋아하는 차 종류 있어?', '무슨 차? 자동차? 마시는 차?')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100797"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data = list(zip(data1['Q'].to_list(), data1['A'].to_list()))\n",
    "print(chat_data[:1])\n",
    "chat_data2 = list(zip(data2['req'].to_list(), data2['res'].to_list()))\n",
    "print(chat_data2[:1])\n",
    "chat_data.extend(chat_data2)\n",
    "len(chat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "623e6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_data():\n",
    "    bos_token = tokenizer.bos_token\n",
    "    eos_token = tokenizer.eos_token\n",
    "    for question, answer in chat_data:\n",
    "        sentence = f\"{bos_token}<usr>{question}<sys>{answer}{eos_token}\"\n",
    "        # print(sentence)\n",
    "        yield tokenizer.encode(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bbc4050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 9349, 7888, 739, 7318, 376, 4, 12557, 6824, 9108, 9028, 7098, 25856, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = get_chat_data()\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f6dcc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_generator(get_chat_data, output_types=tf.int32)\n",
    "\n",
    "dataset = dataset.padded_batch(batch_size=batch_size, padded_shapes=(None,), padding_values=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2cd07",
   "metadata": {},
   "source": [
    "## 학습 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e99e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 설정\n",
    "import keras\n",
    "adam = keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a5068",
   "metadata": {},
   "source": [
    "전이 학습은 learning rate를 아주 작게 설정해, 가중치를 미세하게 조금씩 조금씩 조정한다.\n",
    "\n",
    "- 사전 학습된 가중치 보존이 중요하기 때문 (기존의 가중치가 유용할 것이므로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f76b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m         batch_loss = tf.reduce_mean(result[\u001b[32m0\u001b[39m])\n\u001b[32m     14\u001b[39m         grads = tape.gradient(batch_loss, model.trainable_variables)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m         \u001b[43madam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     train_loss += batch_loss\n\u001b[32m     19\u001b[39m train_loss /= steps\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:463\u001b[39m, in \u001b[36mBaseOptimizer.apply_gradients\u001b[39m\u001b[34m(self, grads_and_vars)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[32m    462\u001b[39m     grads, trainable_variables = \u001b[38;5;28mzip\u001b[39m(*grads_and_vars)\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterations\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:527\u001b[39m, in \u001b[36mBaseOptimizer.apply\u001b[39m\u001b[34m(self, grads, trainable_variables)\u001b[39m\n\u001b[32m    524\u001b[39m     grads = [g \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m g / scale \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads]\n\u001b[32m    526\u001b[39m \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:593\u001b[39m, in \u001b[36mBaseOptimizer._backend_apply_gradients\u001b[39m\u001b[34m(self, grads, trainable_variables)\u001b[39m\n\u001b[32m    590\u001b[39m     \u001b[38;5;28mself\u001b[39m._apply_weight_decay(trainable_variables)\n\u001b[32m    592\u001b[39m     \u001b[38;5;66;03m# Run update step.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend_update_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlearning_rate\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_ema:\n\u001b[32m    598\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_model_variables_moving_average(\n\u001b[32m    599\u001b[39m         \u001b[38;5;28mself\u001b[39m._trainable_variables\n\u001b[32m    600\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\optimizer.py:120\u001b[39m, in \u001b[36mTFOptimizer._backend_update_step\u001b[39m\u001b[34m(self, grads, trainable_variables, learning_rate)\u001b[39m\n\u001b[32m    118\u001b[39m grads_and_vars = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[32m    119\u001b[39m grads_and_vars = \u001b[38;5;28mself\u001b[39m._all_reduce_sum_gradients(grads_and_vars)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__internal__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdistribute\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_distributed_tf_update_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\distribute\\merge_call_interim.py:51\u001b[39m, in \u001b[36mmaybe_merge_call\u001b[39m\u001b[34m(fn, strategy, *args, **kwargs)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[32m     32\u001b[39m \n\u001b[32m     33\u001b[39m \u001b[33;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m \u001b[33;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     53\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m distribute_lib.get_replica_context().merge_call(\n\u001b[32m     54\u001b[39m       fn, args=args, kwargs=kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\optimizer.py:134\u001b[39m, in \u001b[36mTFOptimizer._distributed_tf_update_step\u001b[39m\u001b[34m(self, distribution, grads_and_vars, learning_rate)\u001b[39m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.update_step(grad, var, learning_rate)\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[43mdistribution\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextended\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3005\u001b[39m, in \u001b[36mStrategyExtendedV2.update\u001b[39m\u001b[34m(self, var, fn, args, kwargs, group)\u001b[39m\n\u001b[32m   3002\u001b[39m   fn = autograph.tf_convert(\n\u001b[32m   3003\u001b[39m       fn, autograph_ctx.control_status_ctx(), convert_by_default=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   3004\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._container_strategy().scope():\n\u001b[32m-> \u001b[39m\u001b[32m3005\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3006\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3007\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._replica_ctx_update(\n\u001b[32m   3008\u001b[39m       var, fn, args=args, kwargs=kwargs, group=group)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4075\u001b[39m, in \u001b[36m_DefaultDistributionExtended._update\u001b[39m\u001b[34m(self, var, fn, args, kwargs, group)\u001b[39m\n\u001b[32m   4072\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[32m   4073\u001b[39m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[32m   4074\u001b[39m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4075\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4081\u001b[39m, in \u001b[36m_DefaultDistributionExtended._update_non_slot\u001b[39m\u001b[34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[39m\n\u001b[32m   4077\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[32m   4078\u001b[39m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[32m   4079\u001b[39m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[32m   4080\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[32m-> \u001b[39m\u001b[32m4081\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4082\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[32m   4083\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:596\u001b[39m, in \u001b[36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    595\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.UNSPECIFIED):\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\optimizer.py:131\u001b[39m, in \u001b[36mTFOptimizer._distributed_tf_update_step.<locals>.apply_grad_to_update_var\u001b[39m\u001b[34m(var, grad, learning_rate)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_grad_to_update_var\u001b[39m(var, grad, learning_rate):\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\keras\\src\\optimizers\\adam.py:106\u001b[39m, in \u001b[36mAdam.update_step\u001b[39m\u001b[34m(self, gradient, variable, learning_rate)\u001b[39m\n\u001b[32m    104\u001b[39m lr = ops.cast(learning_rate, variable.dtype)\n\u001b[32m    105\u001b[39m gradient = ops.cast(gradient, variable.dtype)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m local_step = ops.cast(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m, variable.dtype)\n\u001b[32m    107\u001b[39m beta_1_power = ops.power(\n\u001b[32m    108\u001b[39m     ops.cast(\u001b[38;5;28mself\u001b[39m.beta_1, variable.dtype), local_step\n\u001b[32m    109\u001b[39m )\n\u001b[32m    110\u001b[39m beta_2_power = ops.power(\n\u001b[32m    111\u001b[39m     ops.cast(\u001b[38;5;28mself\u001b[39m.beta_2, variable.dtype), local_step\n\u001b[32m    112\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py:476\u001b[39m, in \u001b[36mVariable.__add__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\sparse.py:493\u001b[39m, in \u001b[36melementwise_binary_union.<locals>.wrap_elementwise_binary_union.<locals>.sparse_wrapper\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x2, tf.IndexedSlices):\n\u001b[32m    491\u001b[39m     \u001b[38;5;66;03m# x2 is an IndexedSlices, densify.\u001b[39;00m\n\u001b[32m    492\u001b[39m     x2 = tf.convert_to_tensor(x2)\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py:106\u001b[39m, in \u001b[36madd\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m    101\u001b[39m dtype = dtypes.result_type(\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mgetattr\u001b[39m(x1, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m(x1)),\n\u001b[32m    103\u001b[39m     \u001b[38;5;28mgetattr\u001b[39m(x2, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m(x2)),\n\u001b[32m    104\u001b[39m )\n\u001b[32m    105\u001b[39m x1 = convert_to_tensor(x1, dtype)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m x2 = \u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# Special case of `tf.add`: `tf.nn.bias_add`\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# `BiasAdd` can be fused with `MatMul` and `Conv*` kernels\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# Expecting `x1` to be `inputs` and `x2` to be `bias` (no swapping)\u001b[39;00m\n\u001b[32m    111\u001b[39m x2_squeeze_shape = [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m x2.shape.as_list() \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m d > \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:152\u001b[39m, in \u001b[36mconvert_to_tensor\u001b[39m\u001b[34m(x, dtype, sparse, ragged)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype == \u001b[33m\"\u001b[39m\u001b[33mbool\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_int_dtype(dtype):\n\u001b[32m    148\u001b[39m         \u001b[38;5;66;03m# TensorFlow conversion is stricter than other backends, it does not\u001b[39;00m\n\u001b[32m    149\u001b[39m         \u001b[38;5;66;03m# allow ints for bools or floats for ints. We convert without dtype\u001b[39;00m\n\u001b[32m    150\u001b[39m         \u001b[38;5;66;03m# and cast instead.\u001b[39;00m\n\u001b[32m    151\u001b[39m         x = tf.convert_to_tensor(x)\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.convert_to_tensor(x, dtype=dtype)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m standardize_dtype(x.dtype) == dtype:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1258\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1260\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1262\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1021\u001b[39m, in \u001b[36mcast\u001b[39m\u001b[34m(x, dtype, name)\u001b[39m\n\u001b[32m   1014\u001b[39m     logging.warn(\n\u001b[32m   1015\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou are casting an input of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.dtype.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to an \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1016\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mincompatible dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_type.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.  This will \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdiscard the imaginary part and may not be what you \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mintended.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m     )\n\u001b[32m   1020\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m x.dtype != base_type:\n\u001b[32m-> \u001b[39m\u001b[32m1021\u001b[39m     x = \u001b[43mgen_math_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Desktop\\p_chatbot\\chatbot-dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:2113\u001b[39m, in \u001b[36mcast\u001b[39m\u001b[34m(x, DstT, Truncate, name)\u001b[39m\n\u001b[32m   2111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m   2112\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2113\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2114\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCast\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDstT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDstT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTruncate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTruncate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   2116\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "\n",
    "steps = len(chat_data) // batch_size  # 1 epoch마다 학습할 batch 사이즈\n",
    "epochs = 20  # 너무 오래 걸려서 일단 1회만\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch in dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            result = model(batch, labels=batch)\n",
    "            batch_loss = tf.reduce_mean(result[0])\n",
    "            \n",
    "            grads = tape.gradient(batch_loss, model.trainable_variables)\n",
    "            adam.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        train_loss += batch_loss\n",
    "    \n",
    "    train_loss /= steps\n",
    "\n",
    "    # 조기종료는 하지 않는다.\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"chatbot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
